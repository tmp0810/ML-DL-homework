{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hfbb2nzl9DZ"
      },
      "source": [
        "# **# Pre-processing News Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1elcGz7huoP"
      },
      "source": [
        "## Bài toán\n",
        "Dữ liệu gồm n văn bản phân vào 10 chủ đề khác nhau. Cần biễu diễn mỗi văn bản dưới dạng một vector số thể hiện cho nội dụng của văn bản đó."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyy4DDvuhuoU"
      },
      "source": [
        "## Mục lục\n",
        "- Load dữ liệu từ thư mục\n",
        "- Loại bỏ các stop words\n",
        "- Sử dụng thư viện để mã hóa TF-IDF cho mỗi văn bản"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_akck0KhuoW"
      },
      "source": [
        "## Phương pháp mã hóa: TF-IDF\n",
        "Cho tập gồm $n$ văn bản: $D = \\{d_1, d_2, ... d_n\\}$. Tập từ điển tương ứng được xây dựng từ $n$ văn bản này có độ dài là $m$\n",
        "- Xét văn bản $d$ có $|d|$ từ và $t$ là một từ trong $d$. Mã hóa tf-idf của $t$ trong văn bản $d$ được biểu diễn:\n",
        "\\begin{equation}\n",
        "    \\begin{split}\n",
        "        \\text{tf}_{t, d} &= \\frac{f_t}{|d|} \\\\\n",
        "        \\text{idf}_{t, d} &= \\log\\frac{n}{n_t}, \\ \\ \\ \\ n_t = |\\{d\\in D: t\\in d\\}| \\\\\n",
        "        \\text{tf-idf}_{t d} &= \\text{tf}_{t, d} \\times \\text{idf}_{t, d}\n",
        "    \\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "- Khi đó văn bản $d$ được mã hóa là một vector $m$ chiều. Các từ xuất hiện trong d sẽ được thay bằng giá trị tf-idf tương ứng. Các từ không xuất hiện trong $d$ thì thay là 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyvi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "38RUz4FiP1A1",
        "outputId": "009ce316-e3b2-4013-83d7-519ef7562b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.3.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.5)\n",
            "Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eQuwrwZhuoY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_files\n",
        "from pyvi import ViTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqNL4mwDhuoa"
      },
      "source": [
        "## Load dữ liệu từ thư mục\n",
        "\n",
        "Cấu trúc thư mục như sau\n",
        "\n",
        "- data/news_vnexpress/\n",
        "\n",
        "    - Kinh tế:\n",
        "        - bài báo 1.txt\n",
        "        - bài báo 2.txt\n",
        "    - Pháp luật\n",
        "        - bài báo 3.txt\n",
        "        - bài báo 4.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tty49E_ohuoa"
      },
      "outputs": [],
      "source": [
        "INPUT ='/content/news_vnexpress'\n",
        "os.makedirs(\"images\",exist_ok=True)  # thư mục lưu các các hình ảnh trong quá trình huấn luyện và đánh gía"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# Đường dẫn đến file zip (thay 'your_file.zip' bằng tên file zip bạn đã tải lên)\n",
        "zip_file = 'news_vnexpress.zip'\n",
        "\n",
        "# Giải nén file zip\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lm-8zG8ETR8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru3Ct7Zphuob",
        "outputId": "3b169a67-40e9-4e90-9c55-ba228ebf7afb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Các nhãn và số văn bản tương ứng trong dữ liệu\n",
            "----------------------------------------------\n",
            "thoi-su: 59\n",
            "doi-song: 120\n",
            "giai-tri: 201\n",
            "khoa-hoc: 144\n",
            "kinh-doanh: 262\n",
            "the-thao: 173\n",
            "giao-duc: 105\n",
            "phap-luat: 59\n",
            "suc-khoe: 162\n",
            "du-lich: 54\n",
            "-------------------------\n",
            "Tổng số văn bản: 1339\n"
          ]
        }
      ],
      "source": [
        "# statistics\n",
        "print('Các nhãn và số văn bản tương ứng trong dữ liệu')\n",
        "print('----------------------------------------------')\n",
        "\n",
        "n = 0\n",
        "for label in os.listdir(INPUT):\n",
        "    label_path = os.path.join(INPUT, label)\n",
        "\n",
        "    # Kiểm tra xem đó có phải là thư mục không\n",
        "    if os.path.isdir(label_path):\n",
        "        # Đếm số lượng file trong thư mục con\n",
        "        num_files = len([f for f in os.listdir(label_path) if os.path.isfile(os.path.join(label_path, f))])\n",
        "        print(f'{label}: {num_files}')\n",
        "        n += num_files\n",
        "\n",
        "print('-------------------------')\n",
        "print(f\"Tổng số văn bản: {n}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3tycWTfhuoc",
        "outputId": "704dffc1-d5ec-4fd6-914c-2b457773c0f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mapping:\n",
            "doi-song - 0\n",
            "du-lich - 1\n",
            "giai-tri - 2\n",
            "giao-duc - 3\n",
            "khoa-hoc - 4\n",
            "kinh-doanh - 5\n",
            "phap-luat - 6\n",
            "suc-khoe - 7\n",
            "the-thao - 8\n",
            "thoi-su - 9\n",
            "--------------------------\n",
            "['/content/news_vnexpress/khoa-hoc/00133.txt']\n",
            "[4]\n",
            "['Mời độc giả đặt câu hỏi tại đây\\n']\n",
            "\n",
            "Tổng số  văn bản: 1339\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "data_train = load_files(container_path=INPUT, encoding=\"utf-8\")\n",
        "print('mapping:')\n",
        "for i in range(len(data_train.target_names)):\n",
        "    print(f'{data_train.target_names[i]} - {i}')\n",
        "\n",
        "print('--------------------------')\n",
        "print(data_train.filenames[0:1])\n",
        "# print(data_train.data[0:1])\n",
        "print(data_train.target[0:1])\n",
        "print(data_train.data[0:1])\n",
        "\n",
        "print(\"\\nTổng số  văn bản: {}\" .format( len(data_train.filenames)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU06Y_BKhuoe"
      },
      "source": [
        "## Chuyển dữ liệu dạng text về ma trận (n x m) bằng TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6vG0C2ima31"
      },
      "source": [
        "* Bạn cần viết đoạn mã tương ứng trong cell bên dưới. Theo các bước được gợi ý"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns9j8Hgrhuof",
        "outputId": "8420faee-39d2-40d1-b68d-229a6fdd12df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng từ dừng: 2476\n",
            "['a lô', 'a ha', 'ai', 'ai ai', 'ai nấy', 'ai đó', 'alô', 'amen', 'anh', 'anh ấy']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'lô', 'nấy', 'đó', 'ấy'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Số lượng từ trong từ điển: 13108\n",
            "Kích thước dữ liệu sau khi xử lý: (1339, 13108)\n",
            "Kích thước nhãn tương ứng: (1339,)\n"
          ]
        }
      ],
      "source": [
        "# load dữ liệu các stopwords\n",
        "stopword = ['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh',\n",
        "'anh_ấy']\n",
        "\n",
        "stopwords = [x.strip().replace(\"_\", \" \") for x in stopword]\n",
        "vectorizer_without_stopwords = CountVectorizer()\n",
        "vectorizer_without_stopwords.fit(data_train.data)\n",
        "vocab = vectorizer_without_stopwords.vocabulary_\n",
        "nums_of_stopwords = sum(vocab[word] for word in vocab.keys() if word in stopwords)\n",
        "print(f\"Số lượng từ dừng: {nums_of_stopwords}\")\n",
        "print(stopwords)\n",
        "# Chuyển hoá dữ liệu text về dạng vector TF\n",
        "#     - loại bỏ từ dừng\n",
        "#     - sinh từ điển\n",
        "\n",
        "module_count_vector = CountVectorizer(stop_words=stopwords)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', module_count_vector),\n",
        "    ('tfidf', TfidfTransformer())\n",
        "])\n",
        "\n",
        "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận\n",
        "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array\n",
        "data_preprocessed = pipeline.fit_transform(data_train.data)\n",
        "\n",
        "X = data_preprocessed # thuoc tinh\n",
        "Y = data_train.target #nhan\n",
        "\n",
        "\n",
        "print(f\"\\nSố lượng từ trong từ điển: {len(module_count_vector.vocabulary_)}\")\n",
        "print(f\"Kích thước dữ liệu sau khi xử lý: {X.shape}\")\n",
        "print(f\"Kích thước nhãn tương ứng: {Y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzIuAyLphuoi",
        "outputId": "7c31a935-e02a-416a-9d72-b9ac683648d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         ... 0.         0.11843162 0.        ]]\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "print(X[100].toarray())\n",
        "print(Y[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apf3ulZhhuoi",
        "outputId": "23e09640-e5da-4e38-8e48-214ce7d93a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "428"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "sum(sum(X[100].toarray() != 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FjwPJlfhuoj",
        "outputId": "3848a44b-c87a-41ae-ac91-797261d6c437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 13106)\t0.11843162414954997\n",
            "  (0, 13032)\t0.04318409010538516\n",
            "  (0, 13022)\t0.0289816992496587\n",
            "  (0, 13013)\t0.02101375062808559\n",
            "  (0, 13005)\t0.033179731882307\n",
            "  (0, 13000)\t0.011705168291761488\n",
            "  (0, 12999)\t0.017508728791792248\n",
            "  (0, 12983)\t0.03807257372545188\n",
            "  (0, 12982)\t0.012779456747888558\n",
            "  (0, 12978)\t0.02675675372615028\n",
            "  (0, 12977)\t0.04000600971255874\n",
            "  (0, 12971)\t0.015015225621772483\n",
            "  (0, 12950)\t0.035987232004406254\n",
            "  (0, 12946)\t0.025453356563118226\n",
            "  (0, 12932)\t0.020377869875602708\n",
            "  (0, 12929)\t0.016259863255706847\n",
            "  (0, 12926)\t0.2797263592768559\n",
            "  (0, 12919)\t0.0674435686507365\n",
            "  (0, 12915)\t0.055671052741889375\n",
            "  (0, 12909)\t0.013443487672683833\n",
            "  (0, 12890)\t0.06338967814433386\n",
            "  (0, 12883)\t0.03268120834775442\n",
            "  (0, 12877)\t0.03937801012229831\n",
            "  (0, 12864)\t0.02802162970968281\n",
            "  (0, 12856)\t0.02702855594070607\n",
            "  :\t:\n",
            "  (0, 2121)\t0.02172886026538689\n",
            "  (0, 2111)\t0.022707659194638512\n",
            "  (0, 2085)\t0.012263714907304914\n",
            "  (0, 2060)\t0.0605832856519242\n",
            "  (0, 2048)\t0.03443464303978417\n",
            "  (0, 1868)\t0.04313657347966992\n",
            "  (0, 1789)\t0.03915646764619451\n",
            "  (0, 1784)\t0.0399119160606243\n",
            "  (0, 1632)\t0.019805400051052663\n",
            "  (0, 1591)\t0.02944314429145269\n",
            "  (0, 1529)\t0.01252277036080811\n",
            "  (0, 1271)\t0.013492809584655133\n",
            "  (0, 1219)\t0.04313657347966992\n",
            "  (0, 1209)\t0.08627314695933984\n",
            "  (0, 1194)\t0.04313657347966992\n",
            "  (0, 909)\t0.02797263592768559\n",
            "  (0, 662)\t0.019195050669718126\n",
            "  (0, 418)\t0.041237930557446664\n",
            "  (0, 397)\t0.028858380718548952\n",
            "  (0, 392)\t0.020892778423825503\n",
            "  (0, 269)\t0.02802162970968281\n",
            "  (0, 188)\t0.039810664877639707\n",
            "  (0, 156)\t0.019610602838140145\n",
            "  (0, 100)\t0.017508728791792248\n",
            "  (0, 81)\t0.012823375184355675\n"
          ]
        }
      ],
      "source": [
        "print(X[100])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}